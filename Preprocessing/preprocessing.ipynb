{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf920938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from dgl.data.utils import save_graphs\n",
    "from dgl.data.utils import load_graphs\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b96b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "filename = 'TSMC2014_TKY_UTF-8.txt'\n",
    "TKY = open(filename, 'r')\n",
    "TKY_lines = TKY.readlines()\n",
    "filename = 'TSMC2014_NYC_UTF-8.txt'\n",
    "NYC = open(filename, 'r')\n",
    "NYC_lines = NYC.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50647b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"check-in under 100 delete user, traj under 10 delete POI\"\"\"\n",
    "print(\"===NYC===\")\n",
    "usr_appeared = defaultdict(int)\n",
    "POI_usr = defaultdict(set)\n",
    "POI_appeared = defaultdict(int)\n",
    "for line in NYC_lines:\n",
    "    line = line.split(\"\\t\")\n",
    "    usr_appeared[line[0]]+=1\n",
    "    POI_appeared[line[1]]+=1\n",
    "    POI_usr[line[1]].add(line[0])\n",
    "print(len(NYC_lines))\n",
    "delete_usr_NYC = set()\n",
    "for usr in usr_appeared.keys():\n",
    "    if usr_appeared[usr] < 100:\n",
    "        delete_usr.add(usr)\n",
    "\n",
    "# delete_POI_NYC = set()\n",
    "# for poi in POI_usr.keys():\n",
    "#     if len(POI_usr[poi]) < 10:\n",
    "#         delete_POI_NYC.add(poi)\n",
    "\n",
    "delete_POI_NYC = set()\n",
    "for poi in POI_appeared.keys():\n",
    "    if POI_appeared[poi] < 10:\n",
    "        delete_POI_NYC.add(poi)\n",
    "        \n",
    "print(len(delete_usr_NYC), len(delete_POI_NYC))\n",
    "\n",
    "NYC_out = open('NYC_1st.txt', 'w')\n",
    "cnt = 0\n",
    "for line in NYC_lines:\n",
    "    splitted = line.split(\"\\t\")\n",
    "    if splitted[0] not in delete_usr_NYC and splitted[1] not in delete_POI_NYC:\n",
    "        NYC_out.write(line)\n",
    "        cnt+=1\n",
    "NYC_out.close()\n",
    "NYC.close()\n",
    "print(cnt)\n",
    "\n",
    "print(\"===TKY===\")\n",
    "usr_appeared = defaultdict(int)\n",
    "POI_usr = defaultdict(set)\n",
    "POI_appeared = defaultdict(int)\n",
    "for line in TKY_lines:\n",
    "    line = line.split(\"\\t\")\n",
    "    usr_appeared[line[0]]+=1\n",
    "    POI_appeared[line[1]]+=1\n",
    "    POI_usr[line[1]].add(line[0])\n",
    "print(len(TKY_lines))\n",
    "delete_usr_TKY = set()\n",
    "for usr in usr_appeared.keys():\n",
    "    if usr_appeared[usr] < 10:\n",
    "        delete_usr.add(usr)\n",
    "\n",
    "# delete_POI_TKY = set()\n",
    "# for poi in POI_usr.keys():\n",
    "#     if len(POI_usr[poi]) < 10:\n",
    "#         delete_POI_TKY.add(poi)\n",
    "\n",
    "delete_POI_TKY = set()\n",
    "for poi in POI_appeared.keys():\n",
    "    if POI_appeared[poi] < 10:\n",
    "        delete_POI_TKY.add(poi)\n",
    "        \n",
    "print(len(delete_usr_TKY), len(delete_POI_TKY))\n",
    "\n",
    "TKY_out = open('TKY_1st.txt', 'w')\n",
    "cnt = 0\n",
    "for line in TKY_lines:\n",
    "    splitted = line.split(\"\\t\")\n",
    "    if splitted[0] not in delete_usr_TKY and splitted[1] not in delete_POI_TKY:\n",
    "        TKY_out.write(line)\n",
    "        cnt+=1\n",
    "TKY_out.close()\n",
    "TKY.close()\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c85324",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'TKY_1st.txt'\n",
    "TKY = open(filename, 'r')\n",
    "TKY_lines = TKY.readlines()\n",
    "filename = 'NYC_1st.txt'\n",
    "NYC = open(filename, 'r')\n",
    "NYC_lines = NYC.readlines()\n",
    "\n",
    "\n",
    "print(\"===NYC===\")\n",
    "NYC_out = open('NYC_2nd.txt', 'w')\n",
    "for line in NYC_lines:\n",
    "    line = line.replace(\"+0000\", \"\")\n",
    "    line = line.replace(\"  \", \" \")\n",
    "    line = line.replace(\"Jan\", \"01\")\n",
    "    line = line.replace(\"Feb\", \"02\")\n",
    "    line = line.replace(\"Mar\", \"03\")\n",
    "    line = line.replace(\"Apr\", \"04\")\n",
    "    line = line.replace(\"May\", \"05\")\n",
    "    line = line.replace(\"Jun\", \"06\")\n",
    "    line = line.replace(\"Jul\", \"07\")\n",
    "    line = line.replace(\"Aug\", \"08\")\n",
    "    line = line.replace(\"Sep\", \"09\")\n",
    "    line = line.replace(\"Oct\", \"10\")\n",
    "    line = line.replace(\"Nov\", \"11\")\n",
    "    line = line.replace(\"Dec\", \"12\")\n",
    "    line = line.split(\"\\t\")\n",
    "    line[7] = line[7][4:]\n",
    "    line[7] = line[7][-5:-1] + \" \" + line[7][:-6]\n",
    "    # line[7] = line[7][:10] # drop hour, minute, second\n",
    "    line.append(line[7])\n",
    "    line[7] = line[7][:13] # drop minute, second\n",
    "    NYC_out.write(line[0] + \"\\t\" + line[1] + \"\\t\" +line[2] + \"\\t\" +line[3] + \"\\t\" +line[4] + \"\\t\" +line[5] + \"\\t\" +line[6] + \"\\t\" +line[7] + \"\\t\"+line[8] + \"\\n\")\n",
    "NYC_out.close()\n",
    "NYC.close()\n",
    "print(\"len\",len(NYC_lines))\n",
    "\n",
    "print(\"===TKY===\")\n",
    "TKY_out = open('TKY_2nd.txt', 'w')\n",
    "for line in TKY_lines:\n",
    "    line = line.replace(\"+0000\", \"\")\n",
    "    line = line.replace(\"  \", \" \")\n",
    "    line = line.replace(\"Jan\", \"01\")\n",
    "    line = line.replace(\"Feb\", \"02\")\n",
    "    line = line.replace(\"Mar\", \"03\")\n",
    "    line = line.replace(\"Apr\", \"04\")\n",
    "    line = line.replace(\"May\", \"05\")\n",
    "    line = line.replace(\"Jun\", \"06\")\n",
    "    line = line.replace(\"Jul\", \"07\")\n",
    "    line = line.replace(\"Aug\", \"08\")\n",
    "    line = line.replace(\"Sep\", \"09\")\n",
    "    line = line.replace(\"Oct\", \"10\")\n",
    "    line = line.replace(\"Nov\", \"11\")\n",
    "    line = line.replace(\"Dec\", \"12\")\n",
    "    line = line.split(\"\\t\")\n",
    "    line[7] = line[7][4:]\n",
    "    line[7] = line[7][-5:-1] + \" \" + line[7][:-6]\n",
    "    # line[7] = line[7][:10] # drop hour, minute, second\n",
    "    line.append(line[7])\n",
    "    line[7] = line[7][:13] # drop minute, second\n",
    "    TKY_out.write(line[0] + \"\\t\" + line[1] + \"\\t\" +line[2] + \"\\t\" +line[3] + \"\\t\" +line[4] + \"\\t\" +line[5] + \"\\t\" +line[6] + \"\\t\" +line[7] + \"\\t\"+line[8] + \"\\n\")\n",
    "TKY_out.close()\n",
    "TKY.close()\n",
    "print(len(TKY_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b306b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50df381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"it is an example. you can choose your own time split\"\"\"\n",
    "file_list = ['TKY_2nd.txt','NYC_2nd.txt']\n",
    "for filename in file_list:\n",
    "    print(filename[:-4])\n",
    "    Data = open(filename, 'r')\n",
    "    Data_lines = Data.readlines()\n",
    "\n",
    "    usr_set = set()\n",
    "    POI_set = set()\n",
    "    cat_set = set()\n",
    "    time_set = set()\n",
    "\n",
    "    for line in Data_lines:\n",
    "        line = line.split(\"\\t\")\n",
    "        usr_set.add(line[0])\n",
    "        POI_set.add(line[1])\n",
    "        cat_set.add(line[2])\n",
    "        time_set.add(line[7])\n",
    "    usr_list = list(usr_set)\n",
    "    POI_list = list(POI_set)\n",
    "    cat_list = list(cat_set)\n",
    "    time_list = sorted(list(time_set))\n",
    "    print(time_list[:10])\n",
    "    print(\"user_num:\",len(usr_list),\"POI_num:\", len(POI_list),\"category_num:\", len(cat_list),\"time_num:\", len(time_list))\n",
    "    User_cnt = len(usr_list)\n",
    "    POI_cnt = len(POI_list)\n",
    "    Cat_cnt = len(cat_list)\n",
    "    Time_cnt = len(time_list)\n",
    "    POI_dict = defaultdict(list)\n",
    "    cat_dict = defaultdict(list)\n",
    "    time_dict = defaultdict(list)\n",
    "    cat_txt_dict = defaultdict(list)\n",
    "    coordinate_dict = defaultdict(list)\n",
    "    full_time_dict = defaultdict(list)\n",
    "    for line in tqdm(Data_lines):\n",
    "        line = line.split(\"\\t\")\n",
    "        u = usr_list.index(line[0])\n",
    "        p = User_cnt + POI_list.index(line[1])\n",
    "        c = cat_list.index(line[2])\n",
    "        txt = line[3]\n",
    "        coord = tuple([line[4], line[5]])\n",
    "        t = time_list.index(line[7])\n",
    "        full_t = line[8]\n",
    "        if t < len(time_list)-1-24:\n",
    "            POI_dict[u].append(p)\n",
    "            cat_dict[u].append(c)\n",
    "            time_dict[u].append(t)\n",
    "            cat_txt_dict[u].append(txt)\n",
    "            coordinate_dict[u].append(coord)\n",
    "            full_time_dict[u].append(full_t)\n",
    "    print(len(POI_dict.keys()))\n",
    "    train_users = set(list(POI_dict.keys()))\n",
    "    with open(filename[:-4]+'_train.pickle',\"wb\") as fw:\n",
    "        pickle.dump([User_cnt, POI_cnt, Cat_cnt, Time_cnt, POI_dict, cat_dict, time_dict, cat_txt_dict, coordinate_dict, full_time_dict], fw)\n",
    "    POI_dict = defaultdict(list)\n",
    "    cat_dict = defaultdict(list)\n",
    "    time_dict = defaultdict(list)\n",
    "    test_user_seed = set()\n",
    "    user_future_POIs = defaultdict(set)\n",
    "    user_future_cats = defaultdict(set)\n",
    "    for line in tqdm(Data_lines):\n",
    "        line = line.split(\"\\t\")\n",
    "        u = usr_list.index(line[0])\n",
    "        p = POI_list.index(line[1])\n",
    "        c = cat_list.index(line[2])\n",
    "        txt = line[3]\n",
    "        coord = tuple([line[4], line[5]])\n",
    "        t = time_list.index(line[7])\n",
    "        full_t = line[8]\n",
    "        if t > len(time_list)-1-24-1:\n",
    "            if u in train_users:\n",
    "                test_user_seed.add(u)\n",
    "            POI_dict[u].append(p)\n",
    "            cat_dict[u].append(c)\n",
    "            time_dict[u].append(t)\n",
    "            cat_txt_dict[u].append(txt)\n",
    "            coordinate_dict[u].append(coord)\n",
    "            full_time_dict[u].append(full_t)\n",
    "            user_future_POIs[u].add(p)\n",
    "            user_future_cats[u].add(c)\n",
    "    print(len(POI_dict.keys()))\n",
    "    with open(filename[:-4]+'_test.pickle',\"wb\") as fw:\n",
    "        pickle.dump([test_user_seed, user_future_POIs, user_future_cats, POI_dict, cat_dict, time_dict, cat_txt_dict, coordinate_dict, full_time_dict], fw)\n",
    "    Data.close()\n",
    "    print(len(test_user_seed), \"test user count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c8d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ID\"\"\"\n",
    "file_list = ['TKY_2nd.txt','NYC_2nd.txt']\n",
    "for filename in file_list:\n",
    "    print(filename[:-4])\n",
    "    Data = open(filename, 'r')\n",
    "    Data_lines = Data.readlines()\n",
    "\n",
    "    # idí™”\n",
    "    usr_set = set()\n",
    "    POI_set = set()\n",
    "    cat_set = set()\n",
    "    time_set = set()\n",
    "\n",
    "    for line in Data_lines:\n",
    "        line = line.split(\"\\t\")\n",
    "        usr_set.add(line[0])\n",
    "        POI_set.add(line[1])\n",
    "        cat_set.add(line[2])\n",
    "        time_set.add(line[7])\n",
    "    usr_list = list(usr_set)\n",
    "    POI_list = list(POI_set)\n",
    "    cat_list = list(cat_set)\n",
    "    time_list = sorted(list(time_set))\n",
    "    print(time_list[:10])\n",
    "    print(\"user_num:\",len(usr_list),\"POI_num:\", len(POI_list),\"category_num:\", len(cat_list),\"time_num:\", len(time_list))\n",
    "    Data_out = open(filename[:-4]+'_id.txt', 'w')\n",
    "    for line in tqdm(Data_lines):\n",
    "        line = line.split(\"\\t\")\n",
    "        line[0] = str(usr_list.index(line[0]))\n",
    "        line[1] = str(POI_list.index(line[1]))\n",
    "        line[2] = str(cat_list.index(line[2]))\n",
    "        line[7] = str(time_list.index(line[7]))\n",
    "        Data_out.write(line[0] + \"\\t\" + line[1] + \"\\t\" +line[2] + \"\\t\" +line[3] + \"\\t\" +line[4] + \"\\t\" +line[5] + \"\\t\" +line[6] + \"\\t\" +line[7] + \"\\n\")\n",
    "    Data_out.close()\n",
    "    Data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b991c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"making TKG graph only for training\"\"\"\n",
    "file_list = ['TKY_Hour_id.txt','NYC_Hour_id.txt']\n",
    "for filename in file_list:\n",
    "    Data = open(filename, 'r')\n",
    "    print(filename[:-7])\n",
    "    if filename[:4] == \"NYC\":\n",
    "        ent_num = 6218\n",
    "        user_num = 1083\n",
    "        cat_num = 321\n",
    "    else:\n",
    "        ent_num = 10166\n",
    "        user_num = 2293\n",
    "        cat_num = 292\n",
    "    Data_lines = Data.readlines()\n",
    "    src_ids = []\n",
    "    dst_ids = []\n",
    "    cat_ids = []\n",
    "    time_ids = []\n",
    "    for line in Data_lines:\n",
    "        line = line.split(\"\\t\")\n",
    "        if int(line[7]) < len(time_list)-1-24:\n",
    "            # original\n",
    "            src_ids.append(int(line[0]))\n",
    "            dst_ids.append(user_num + int(line[1]))\n",
    "            cat_ids.append(int(line[2]))\n",
    "            time_ids.append(int(line[7]))\n",
    "            # reciprocal\n",
    "            src_ids.append(user_num + int(line[1]))\n",
    "            dst_ids.append(int(line[0]))\n",
    "            cat_ids.append(cat_num + int(line[2]))\n",
    "            time_ids.append(int(line[7]))\n",
    "    src_ids = torch.tensor(src_ids)\n",
    "    dst_ids = torch.tensor(dst_ids)\n",
    "    cat_ids = torch.tensor(cat_ids)\n",
    "    time_ids = torch.tensor(time_ids)\n",
    "    g = dgl.graph((src_ids, dst_ids), num_nodes=ent_num)\n",
    "    g.ndata['ent_id'] = torch.tensor(list(range(ent_num)))\n",
    "    g.edata['cat_id'] = cat_ids\n",
    "    g.edata['time_id'] = time_ids\n",
    "    print(g)\n",
    "    print(g.edata['time_id'])\n",
    "    graph_labels = {filename[:-7]: torch.tensor([0])}\n",
    "    save_graphs(filename[:-7]+\"_train_-1-24.TKG\", [g], graph_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f623c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "glist, _ = load_graphs(\"TKY_Hour_train_-1-24.TKG\", [0]) # glist will be [g1]\n",
    "Train_graph = glist[0]\n",
    "Train_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3a10458",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "graph_at_i = Train_graph.edge_subgraph(np.where(Train_graph.edata['time_id'] == i)[0], relabel_nodes = False, store_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64d55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_at_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c0dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_at_i.edata['cat_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0632aa0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
